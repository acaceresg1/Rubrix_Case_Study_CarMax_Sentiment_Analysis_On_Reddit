{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d018ede1-93e5-44f7-a8b8-ea8436d063c1",
   "metadata": {},
   "source": [
    "# We are going to build and fine-tune a sentiment classifier from scratch to classify our 1M reddit posts and +3M reddit comments.\n",
    "\n",
    "- First we need to upload our scrapped data\n",
    "\n",
    "- We apply spicy to create a list with all the comments splitted by sentences. We do this because the sentiment classifier was designed to work by sentencem, instead of full comments.\n",
    "\n",
    "- We are going to tune the most popular sentiment classifier on the Hugging Face Hub which has been fine-tuned on the SST2 sentiment dataset, the distilbert-base-uncased-finetuned-sst-2-english.\n",
    "\n",
    "- Label a training dataset of a shuffle sample of all the comments from our subreddit \"whatcarshouldIbuy\" as baseline to get an initial pre-trained sentiment classifier predictions.\n",
    "\n",
    "- Fine-tune the pre-trained classifier with your training dataset. We upload the sample to Rubrix and we label a % of it. To do this we created a new label \"NEUTRAL\", as the original one has only a binary predictors (\"POSITIVE\" and \"NEGATIVE\")\n",
    "\n",
    "- Label more data by correcting the predictions of the fine-tuned model.\n",
    "\n",
    "- Fine-tune the pre-trained classifier with the extended training dataset.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We will fine-tune a sentiment classifier for our used-car domain, starting with no labeled data. The schema of the process is the following\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8572c032",
   "metadata": {},
   "source": [
    "### Uploading our scrapping datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375bde19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import rubrix as rb\n",
    "#!python -m spacy download \"en_core_web_sm\"\n",
    "#spacy option!\n",
    "import spacy\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "from datasets import load_metric\n",
    "from transformers import TrainingArguments\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f2feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv(\"scraped_reddit_posts_for_whatcarshouldIbuy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2b9792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_link</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post keywords</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>top_comment</th>\n",
       "      <th>comment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>whatcarshouldIbuy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5fsq70</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ChalkPie</td>\n",
       "      <td>≤$9k and &lt;50k miles?</td>\n",
       "      <td>I've been driving the same car since I started...</td>\n",
       "      <td>I've seen a few Ford Focus/Hyundai Accent seda...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>whatcarshouldIbuy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5fsfy7</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>everreadyy</td>\n",
       "      <td>buying a new car and feel overwhelmed</td>\n",
       "      <td>I am about to go on a cross-country road trip ...</td>\n",
       "      <td>Insurance should be the same, as the $130 you ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>whatcarshouldIbuy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5frt0p</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>thecw</td>\n",
       "      <td>Replacement for a 2006 Mariner</td>\n",
       "      <td>Hi all,\\nMy wife and I have a 2006 Mercury Mar...</td>\n",
       "      <td>I'd go for a Toyota Rav4 or Honda CRV. Both wi...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>whatcarshouldIbuy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5frs4b</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>chy_vak</td>\n",
       "      <td>Cheapest car to insure?</td>\n",
       "      <td>Hey guys, not sure if this is the right place ...</td>\n",
       "      <td>Chevy Impala's are pretty good on insurance, a...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>whatcarshouldIbuy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5frs37</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>113.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>sockrocker</td>\n",
       "      <td>Optimizing your car search: A few tips I wish ...</td>\n",
       "      <td>**Background**: I just bought a used car. I sp...</td>\n",
       "      <td>You missed the most import step by far:\\n**11a...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_link          subreddit  \\\n",
       "0  https://www.reddit.com/r/whatcarshouldIbuy/com...  whatcarshouldIbuy   \n",
       "1  https://www.reddit.com/r/whatcarshouldIbuy/com...  whatcarshouldIbuy   \n",
       "2  https://www.reddit.com/r/whatcarshouldIbuy/com...  whatcarshouldIbuy   \n",
       "3  https://www.reddit.com/r/whatcarshouldIbuy/com...  whatcarshouldIbuy   \n",
       "4  https://www.reddit.com/r/whatcarshouldIbuy/com...  whatcarshouldIbuy   \n",
       "\n",
       "   post keywords      id        date  score  num_comments      author  \\\n",
       "0            NaN  5fsq70  2016-11-30    3.0           5.0    ChalkPie   \n",
       "1            NaN  5fsfy7  2016-11-30    3.0           2.0  everreadyy   \n",
       "2            NaN  5frt0p  2016-11-30    1.0           3.0       thecw   \n",
       "3            NaN  5frs4b  2016-11-30    1.0           6.0     chy_vak   \n",
       "4            NaN  5frs37  2016-11-30  113.0          12.0  sockrocker   \n",
       "\n",
       "                                               title  \\\n",
       "0                               ≤$9k and <50k miles?   \n",
       "1              buying a new car and feel overwhelmed   \n",
       "2                     Replacement for a 2006 Mariner   \n",
       "3                            Cheapest car to insure?   \n",
       "4  Optimizing your car search: A few tips I wish ...   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  I've been driving the same car since I started...   \n",
       "1  I am about to go on a cross-country road trip ...   \n",
       "2  Hi all,\\nMy wife and I have a 2006 Mercury Mar...   \n",
       "3  Hey guys, not sure if this is the right place ...   \n",
       "4  **Background**: I just bought a used car. I sp...   \n",
       "\n",
       "                                         top_comment  comment_score  \n",
       "0  I've seen a few Ford Focus/Hyundai Accent seda...            1.0  \n",
       "1  Insurance should be the same, as the $130 you ...            2.0  \n",
       "2  I'd go for a Toyota Rav4 or Honda CRV. Both wi...            2.0  \n",
       "3  Chevy Impala's are pretty good on insurance, a...            3.0  \n",
       "4  You missed the most import step by far:\\n**11a...           22.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b590da9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (2,5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "comments = pd.read_csv(\"scraped_reddit_comments_for_whatcarshouldIbuy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6882dd57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_559xc5</td>\n",
       "      <td>d88vp4i</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-30 22:10:09</td>\n",
       "      <td>Torque is what will help a car ascent a steep ...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-09-30 22:10:09</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1_d88vp4i</td>\n",
       "      <td>d8b3wiq</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-02 19:07:45</td>\n",
       "      <td>Thank you.\\nI don't really have the option of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nyxelestia</td>\n",
       "      <td>2016-10-02 19:07:45</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1_d8b3wiq</td>\n",
       "      <td>d8cah3g</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-03 16:38:21</td>\n",
       "      <td>I would aim for the larger engine options with...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-10-03 16:38:21</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_d8cah3g</td>\n",
       "      <td>d8d1dnj</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-04 02:40:55</td>\n",
       "      <td>This is so helpful, thank you! :)\\nOut of curi...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nyxelestia</td>\n",
       "      <td>2016-10-04 02:40:55</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_d8d1dnj</td>\n",
       "      <td>d8dpmsl</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-04 16:33:02</td>\n",
       "      <td>An Accord will drive smoother/quieter than a C...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-10-04 16:33:02</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parent_id comment_id score_id          created_utc  \\\n",
       "0   t3_559xc5    d88vp4i        2  2016-09-30 22:10:09   \n",
       "1  t1_d88vp4i    d8b3wiq        1  2016-10-02 19:07:45   \n",
       "2  t1_d8b3wiq    d8cah3g        1  2016-10-03 16:38:21   \n",
       "3  t1_d8cah3g    d8d1dnj        1  2016-10-04 02:40:55   \n",
       "4  t1_d8d1dnj    d8dpmsl        2  2016-10-04 16:33:02   \n",
       "\n",
       "                                                body score  \\\n",
       "0  Torque is what will help a car ascent a steep ...     2   \n",
       "1  Thank you.\\nI don't really have the option of ...     1   \n",
       "2  I would aim for the larger engine options with...     1   \n",
       "3  This is so helpful, thank you! :)\\nOut of curi...     1   \n",
       "4  An Accord will drive smoother/quieter than a C...     2   \n",
       "\n",
       "                                           permalink is_submitter      author  \\\n",
       "0  /r/whatcarshouldIbuy/comments/559xc5/car_with_...        False    pinks1ip   \n",
       "1  /r/whatcarshouldIbuy/comments/559xc5/car_with_...         True  Nyxelestia   \n",
       "2  /r/whatcarshouldIbuy/comments/559xc5/car_with_...        False    pinks1ip   \n",
       "3  /r/whatcarshouldIbuy/comments/559xc5/car_with_...         True  Nyxelestia   \n",
       "4  /r/whatcarshouldIbuy/comments/559xc5/car_with_...        False    pinks1ip   \n",
       "\n",
       "                  date                                               link  \n",
       "0  2016-09-30 22:10:09  https://www.reddit.com/r/whatcarshouldIbuy/com...  \n",
       "1  2016-10-02 19:07:45  https://www.reddit.com/r/whatcarshouldIbuy/com...  \n",
       "2  2016-10-03 16:38:21  https://www.reddit.com/r/whatcarshouldIbuy/com...  \n",
       "3  2016-10-04 02:40:55  https://www.reddit.com/r/whatcarshouldIbuy/com...  \n",
       "4  2016-10-04 16:33:02  https://www.reddit.com/r/whatcarshouldIbuy/com...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c901a",
   "metadata": {},
   "source": [
    "#### Drop na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9e1c68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f00dd2",
   "metadata": {},
   "source": [
    "### Sentiment Analysis pre-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35115c60",
   "metadata": {},
   "source": [
    "Model: sentiment distilbert fine-tuned on sst-2\n",
    "As of December 2021, the distilbert-base-uncased-finetuned-sst-2-english is in the top five of the most popular text-classification models in the Hugging Face Hub.\n",
    "\n",
    "This model is a distilbert model fine-tuned on SST-2 (Stanford Sentiment Treebank), a highly popular sentiment classification benchmark.\n",
    "\n",
    "This is a general-purpose sentiment classifier, which will need further fine-tuning for specific use cases and styles of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9360ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier = pipeline(\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    task=\"sentiment-analysis\", \n",
    "    return_all_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d28e3",
   "metadata": {},
   "source": [
    "### Sentencizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791a5f98",
   "metadata": {},
   "source": [
    "##### Creation of the sentencizer aplying it over the 100 sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d7ae8",
   "metadata": {},
   "source": [
    "First step is to divide all the comments by sentences. We are going to train our sentiment classifier per sentence, and later, we will pass it over the whole column of comments, adding the sentiment classification as a new column of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e41adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71807638",
   "metadata": {},
   "source": [
    "To train Rubrix We get a random sample of 100k of the comments, and we prepare the dataset to upload it to the Rubrix server. This is a flat list with all the sentences splitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d576a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_for_rubrix = []\n",
    "for text in comments[\"body\"].sample(100000):\n",
    "    doc=nlp(text)\n",
    "    sentences = [sentence.text for sentence in doc.sents]\n",
    "    sentences_for_rubrix += sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db32c5",
   "metadata": {},
   "source": [
    "Sentiment prediction per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_into_sentences_to_label1, txt_into_sentences_to_label2 = train_test_split(sentences_for_rubrix, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a760172",
   "metadata": {},
   "source": [
    "## 1. Run the **pre-trained model** over the dataset and log the predictions\n",
    "\n",
    "First step: we use the pre-trained model for predicting over our raw dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = []\n",
    "for element in txt_into_sentences_to_label1[0:100000]:\n",
    "        sample_txt.append({\"text\":element, \"predictions\": sentiment_classifier(element, truncation=True)}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594a8f8d",
   "metadata": {},
   "source": [
    "We create the Rubrix dataset for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt_rb = []\n",
    "for item in sample_txt:\n",
    "    sample_txt_ = rb.TextClassificationRecord(\n",
    "        text=item[\"text\"],\n",
    "        #metadata={'title_id': item['title_id'], \"title\": item[\"title\"]}, # log the intents for exploration of specific intents\n",
    "        prediction=[(pred['label'], pred['score']) for pred in item['predictions'][0]],\n",
    "        prediction_agent=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "    sample_txt_rb.append(sample_txt_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rb = rb.DatasetForTextClassification(sample_txt_rb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e70fe0",
   "metadata": {},
   "source": [
    "We upload everything to Rubrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(name='cars_sentence_with_pretrained_for_neutral', records=dataset_rb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ed970",
   "metadata": {},
   "source": [
    "## 2. Explore and label data with the pretrained model\n",
    "\n",
    "In this step, we'll start by exploring how the pre-trained model is performing with our dataset. \n",
    "\n",
    "At first sight:\n",
    "\n",
    "- The pre-trained sentiment classifier only has 'POSITIVE' and 'NEGATIVE', and after checking the comments, we consider that it is needed a NEUTRAL LABEL\n",
    "\n",
    "- The prediction per comment tends to be NEGATIVE-(60%), POSITIVE(40%).\n",
    "\n",
    "- Labelling RULES:\n",
    "    * A recommendation of a car/cars brand or model/models is considered POSITIVE\n",
    "    * A selection of some cars of a list (are in the titles) are considered POSTIIVE\n",
    "    * If the comment has something like: I love the car, but there is only one problem, is POSITIVE\n",
    "    * If the comment has something like: I hate the car, but there is only one thing good, is NEGATIVE.\n",
    "    * If has a balance with the some negatives and some positives, is NEUTRAL\n",
    "    * If it speaks about something around cars without influence, is NEUTRAL\n",
    "    * Questions about reliability or models or whatever is NEUTRAL\n",
    "    * Questions about problems, are NEGATIVES\n",
    "    * Questions about good features are POSITIVES\n",
    "    \n",
    "Taking into account this RULES, we can start labeling our data. \n",
    "\n",
    "Rubrix provides you with a search-driven UI to annotated data, using **free-text search**, **search filters** and **the Elasticsearch query DSL** for advanced queries. This is especially useful for sparse datasets, tasks with a high number of labels, or unbalanced classes. In the standard case, we recommend you to follow the workflow below:\n",
    "\n",
    "1. **Start labeling examples sequentially**, without using search features. This way you will annotate a fraction of your data which will be aligned with the dataset distribution.\n",
    "\n",
    "2. Once you have a sense of the data, you can **start using filters and search features to annotate examples with specific labels**. In our case, we'll label examples predicted as `POSITIVE` by our pre-trained model, and then a few examples predicted as `NEGATIVE`.\n",
    "\n",
    "3. In our case as we add a NEUTRAL label, we need to label more to train this new NEUTRAL label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b490f7",
   "metadata": {},
   "source": [
    "### We have uploaded to rubrix the first 100000 senteces of our sample_txt list. The dataset is huge so we need to reduce resources as is super time consuming.\n",
    "### After upload it, we have validated and labeled by hand around 1000 records, a 1% of those 100000, and we tuned the baseline classifier with those new inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f4547",
   "metadata": {},
   "source": [
    "## 3. Fine-tune the pre-trained model\n",
    "\n",
    "\n",
    "First, let's load the annotations from our dataset using the query parameter from the `load` method. The `Validated` status corresponds to annotated records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2382b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_dataset = rb.load(name='cars_sentence_with_pretrained_for_neutral', query=\"status:Validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd957f61",
   "metadata": {},
   "source": [
    "##### Creating and preparing our train and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78009381",
   "metadata": {},
   "source": [
    "Let's now prepare our dataset for training and testing our sentiment classifier, using the `datasets` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee65b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 🤗 dataset with labels as numeric ids\n",
    "train_ds = rb_dataset.prepare_for_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24973129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1012\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aada2f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4743af12df9c43a3a577134af0b002ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize our datasets\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_train_ds = train_ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9c98e",
   "metadata": {},
   "source": [
    "We split the data into a training and evalutaion set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8180dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = tokenized_train_ds.train_test_split(test_size=0.2, seed=42).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99219953",
   "metadata": {},
   "source": [
    "### Train our sentiment classifier\n",
    "\n",
    "As we mentioned before, we're going to fine-tune the `distilbert-base-uncased-finetuned-sst-2-english` model. \n",
    "We load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a3214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels = 3, ignore_mismatched_sizes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1260e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"distilbert-base-uncased-sentiment_cars\", \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=30,\n",
    ")\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average = \"micro\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    model=model, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=eval_dataset, \n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee52fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703d9a4-bfce-466f-accc-65f65a784f2d",
   "metadata": {},
   "source": [
    "## 4. Testing the fine-tuned model\n",
    "\n",
    "In this step, let's first test the model we have just trained.\n",
    "\n",
    "Let's create a new pipeline with our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa3305-78bc-4316-a886-0c5b3e95d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_sentiment_classifier = pipeline(\n",
    "    model=model.to(\"cpu\"),\n",
    "    tokenizer=tokenizer, \n",
    "    task=\"sentiment-analysis\", \n",
    "    return_all_scores=True,\n",
    "    truncation = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde2089",
   "metadata": {},
   "source": [
    "LABEL_0 = NEGATIVE, LABEL_1 = NEUTRAL, LABEL_2 = POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2a5aa",
   "metadata": {},
   "source": [
    "#### Then, we can compare its predictions with the pre-trained model and an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ef8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_sentiment_classifier(\n",
    "                        'Always consider your insurance costs, whichever car you choose.'\n",
    "), sentiment_classifier('Always consider your insurance costs, whichever car you choose.'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_sentiment_classifier(\n",
    "                        'I only buy Toyota/Lexus for reliability reasons.'\n",
    "), sentiment_classifier('I only buy Toyota/Lexus for reliability reasons.'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f4093",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_sentiment_classifier(\n",
    "                        'I got my 2013 BMW 335i M-Sport with almost every option, ~18000 miles for $35k'\n",
    "), sentiment_classifier('I got my 2013 BMW 335i M-Sport with almost every option, ~18000 miles for $35k'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1aac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_sentiment_classifier(\n",
    "'BMWs lease really well, too, so if you want a BMW I would strongly advise leasing one.'\n",
    "), sentiment_classifier('BMWs lease really well, too, so if you want a BMW I would strongly advise leasing one.'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1856c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_sentiment_classifier(\n",
    "    'I spent another ~$2k for the new shocks, tires, replaced the rear sway bar, got the free recalls done, and now I have a car I love for a grand total of $10k, half my initial budget.'\n",
    "), sentiment_classifier(\n",
    "    'I spent another ~$2k for the new shocks, tires, replaced the rear sway bar, got the free recalls done, and now I have a car I love for a grand total of $10k, half my initial budget.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f9ca1",
   "metadata": {},
   "source": [
    "## 5. Run our **fine-tuned model** over the dataset and log the predictions\n",
    "\n",
    "\n",
    "Let's now create a dataset from the remaining records (those which we haven't annotated in the first annotation session).\n",
    "\n",
    "We'll do this using the `Default` status, which means the record hasn't been assigned a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b9fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_dataset = rb.load(name='cars_sentence_with_pretrained_for_neutral', query=\"status:Default\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e2743",
   "metadata": {},
   "source": [
    "#### HE HECHO TODO ESTO, RETUNEAMOS EL CLASSIFIER PERO AHORA CON TRES LABELS!\n",
    "\n",
    "From here, this is basically the same as step 1, in this case using our fine-tuned model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ac201",
   "metadata": {},
   "source": [
    "Let's take advantage of the datasets map feature, to make batched predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700df643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(examples):\n",
    "    texts = [example[\"text\"] for example in examples[\"inputs\"]]\n",
    "    return {\n",
    "        \"prediction\": finetuned_sentiment_classifier(texts), \n",
    "        \"prediction_agent\": [\"distilbert-base-uncased-sentiment-car\"]*len(texts)\n",
    "    }\n",
    "\n",
    "ds_dataset = rb_dataset.to_datasets().map(predict, batched=True, batch_size=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce6de1",
   "metadata": {},
   "source": [
    "Afterward, we can convert the dataset directly to Rubrix records again and log them to the web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = rb.read_datasets(ds_dataset, task=\"TextClassification\")\n",
    "\n",
    "rb.log(records=records, name='car_labeling_with_finetune_neutral_to_improve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd6cd4",
   "metadata": {},
   "source": [
    "## 6. Explore and label data with the fine-tuned model\n",
    "\n",
    "\n",
    "In this step, we'll start by exploring how the fine-tuned model is performing with our dataset and we label again a few number of sentences to refine more our classifier.\n",
    "\n",
    "We labelled more than 300 annotated examples.\n",
    "\n",
    "Let's add our new examples to our previous training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df38104",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_dataset = rb.load(\"car_labeling_with_finetune_neutral_to_improve\")\n",
    "\n",
    "mapping = {\n",
    "    \"LABEL_0\": \"NEGATIVE\",\n",
    "    \"LABEL_1\": \"NEUTRAL\",\n",
    "    \"LABEL_2\": \"POSITIVE\"\n",
    "}\n",
    "for record in rb_dataset:\n",
    "  # skip unlabeled records\n",
    "  if not record.annotation:\n",
    "    continue\n",
    "\n",
    "  record.annotation = mapping[record.annotation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "253ce7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\fredi/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/vocab.txt from cache at C:\\Users\\fredi/.cache\\huggingface\\transformers\\83261b0c74c462e53d6367de0646b1fca07d0f15f1be045156b9cf8c71279cc9.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/tokenizer_config.json from cache at C:\\Users\\fredi/.cache\\huggingface\\transformers\\d44ec0488a5f13d92b3934cb68cc5849bd74ce63ede2eea2bf3c675e1e57297c.627f9558061e7bc67ed0f516b2f7efc1351772cc8553101f08748d44aada8b11\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\fredi/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\fredi/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdee60d98504d859eba8053cc4f901e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = rb_dataset.prepare_for_training()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_train_ds = train_ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ae4d8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=3, names=['NEGATIVE', 'NEUTRAL', 'POSITIVE'], id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_ds.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31e21c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=3, names=['NEGATIVE', 'NEUTRAL', 'POSITIVE'], id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2643129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "train_dataset = concatenate_datasets([train_dataset, tokenized_train_ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96cf05",
   "metadata": {},
   "source": [
    "As we want to measure the effect of adding examples to our training set we will:\n",
    "\n",
    "Fine-tune from the pre-trained sentiment weights (as we did before)\n",
    "Use the previous test set and the extended train set (obtaining a metric we use to compare this new version with our previous model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bd526f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/config.json from cache at C:\\Users\\fredi/.cache\\huggingface\\transformers\\4e60bb8efad3d4b7dc9969bf204947c185166a0a3cf37ddb6f481a876a3777b5.9f8326d0b7697c7fd57366cdde57032f46bc10e37ae81cb7eb564d66d23ec96b\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/resolve/main/pytorch_model.bin from cache at C:\\Users\\fredi/.cache\\huggingface\\transformers\\8d04c767d9d4c14d929ce7ad8e067b80c74dbdb212ef4c3fb743db4ee109fae0.9d268a35da669ead745c44d369dc9948b408da5010c6bac414414a7e33d5748c\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels = 3, ignore_mismatched_sizes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc4cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dataset.shuffle(seed=42)\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    model=model, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=eval_dataset, \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "964141c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\fredi\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1487\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 558\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='558' max='558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [558/558 1:22:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.609800</td>\n",
       "      <td>0.877583</td>\n",
       "      <td>0.645320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>1.167308</td>\n",
       "      <td>0.635468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>1.370419</td>\n",
       "      <td>0.655172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to distilbert-base-uncased-sentiment_cars\\checkpoint-500\n",
      "Configuration saved in distilbert-base-uncased-sentiment_cars\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-sentiment_cars\\checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=558, training_loss=0.4252532032655559, metrics={'train_runtime': 4980.3513, 'train_samples_per_second': 0.896, 'train_steps_per_second': 0.112, 'total_flos': 590947603928064.0, 'train_loss': 0.4252532032655559, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22ad52",
   "metadata": {},
   "source": [
    "Finally we saved our model tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "257c54df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in distilbert-base-uncased-sentiment-car_with_neutral\\config.json\n",
      "Model weights saved in distilbert-base-uncased-sentiment-car_with_neutral\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"distilbert-base-uncased-sentiment-car_with_neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdada407",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_car_sentiment_classifier_tuned_for_testing = pipeline(\n",
    "    model=model.to(\"cpu\"),\n",
    "    tokenizer=tokenizer, \n",
    "    task=\"sentiment-analysis\", \n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2530f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{'label': 'LABEL_0', 'score': 0.01840960793197155},\n",
       "   {'label': 'LABEL_1', 'score': 0.9537872076034546},\n",
       "   {'label': 'LABEL_2', 'score': 0.027803298085927963}]],\n",
       " [[{'label': 'NEGATIVE', 'score': 0.726030170917511},\n",
       "   {'label': 'POSITIVE', 'score': 0.2739698588848114}]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_car_sentiment_classifier_tuned_for_testing(\n",
    "    \"Rx8 is always an option if you like checking your oil at every tank up.\"\n",
    "), sentiment_classifier(\n",
    "    \"Rx8 is always an option if you like checking your oil at every tank up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4cf4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{'label': 'LABEL_0', 'score': 0.8444103598594666},\n",
       "   {'label': 'LABEL_1', 'score': 0.10671481490135193},\n",
       "   {'label': 'LABEL_2', 'score': 0.04887479916214943}]],\n",
       " [[{'label': 'NEGATIVE', 'score': 0.977379322052002},\n",
       "   {'label': 'POSITIVE', 'score': 0.02262074500322342}]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_car_sentiment_classifier_tuned_for_testing(\n",
    "    \"The seats of the Infiniti feel like they were made for a medium sized Asian man.\"\n",
    "), sentiment_classifier(\n",
    "    \"The seats of the Infiniti feel like they were made for a medium sized Asian man.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50996fc5",
   "metadata": {},
   "source": [
    "## 5. Now its time to make the sentiment of the entire comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac613f",
   "metadata": {},
   "source": [
    "Here we divide the comment per sentence, creating a new column in our dataset as we need to the sentiment per sentence and later we sum the sentiment result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "78d9bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_into_sentences = []\n",
    "for text in comments[\"body\"]:\n",
    "    doc=nlp(text)\n",
    "    sentences = [sentence.text for sentence in doc.sents]\n",
    "    comment_into_sentences.append(sentences)\n",
    "\n",
    "comments[\"body_splitted\"] = comment_into_sentences   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0cf39958",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_json(\"comments_splitted.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3307d",
   "metadata": {},
   "source": [
    "First, we save our last model as the good one. And we do the sentiment per comment and sentence, getting a list per comment with all the sentiments per sentences. Later we use this sentiment to calculate how good/bad/neutral is the sentiment per comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f7cca17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_car_sentiment_classifier_tuned_for_op = pipeline(\n",
    "    model=model.to(\"cpu\"),\n",
    "    tokenizer=tokenizer, \n",
    "    task=\"sentiment-analysis\", \n",
    "    return_all_scores=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7017514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "300000\n",
      "600000\n",
      "900000\n",
      "1100000\n"
     ]
    }
   ],
   "source": [
    "sentiment_numbers = []\n",
    "for comment in comments[\"body_splitted\"]:\n",
    "    sentiment = final_car_sentiment_classifier_tuned_for_op(comment, truncation = True)\n",
    "    sentiment_numbers.append(sentiment)\n",
    "    if (len(sentiment_numbers)==100000 or len(sentiment_numbers)==300000 or len(sentiment_numbers)==600000 or len(sentiment_numbers)==900000 or len(sentiment_numbers)==1100000):\n",
    "        print(len(sentiment_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "332fbaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[\"sentiment\"] = sentiment_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "26d8f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_json(\"comments_splitted_sentiment.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ae70d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_json(\"comments_splitted_sentiment.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f57944",
   "metadata": {},
   "source": [
    "Now we count the number of negatives and positives per comment, and we average the result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941841e",
   "metadata": {},
   "source": [
    "First approach, we average the sum dividing by the total number of sentences in the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0d9b2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count = []\n",
    "for comment in comments[\"sentiment\"]:\n",
    "    sentiment_number = 0\n",
    "    for sentiment in comment:\n",
    "        if sentiment[\"label\"] == \"LABEL_2\":\n",
    "            sentiment_number +=1\n",
    "        elif sentiment[\"label\"] == \"LABEL_0\":\n",
    "            sentiment_number +=-1\n",
    "    sentiment_of_comment = sentiment_number/len(comment)    \n",
    "    sentiment_count.append(sentiment_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "026a46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[\"sentiment_score\"] = sentiment_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7714a0",
   "metadata": {},
   "source": [
    "Second approach: Instead of dividing by the number of sentences in the comment, we divide by the avg number of sentences per comment in the dataset. Why would be beneficial?\n",
    "We consider that if someone spend time explaining things and givinig a highly positive comment or a highly negative comment, would be good to get it. The only way of doing that is giving more weight to the posts with more sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0050ede9",
   "metadata": {},
   "source": [
    "This is the code to calculate the avg number of sentences per comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "86862988",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 0\n",
    "for item in comments[\"body_splitted\"]:\n",
    "    avg += len(item)/len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "705e437c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.286314331600568"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f7b6022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count2 = []\n",
    "for comment in comments[\"sentiment\"]:\n",
    "    sentiment_number2 = 0\n",
    "    for sentiment in comment:\n",
    "        if sentiment[\"label\"] == \"LABEL_2\":\n",
    "            sentiment_number2 +=1\n",
    "        elif sentiment[\"label\"] == \"LABEL_0\":\n",
    "            sentiment_number2 +=-1\n",
    "    sentiment_of_comment2 = sentiment_number2/avg   \n",
    "    sentiment_count2.append(sentiment_of_comment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7e30d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[\"sentiment_score_avg\"] = sentiment_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e66547d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>body_splitted</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_score_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_559xc5</td>\n",
       "      <td>d88vp4i</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-30 22:10:09</td>\n",
       "      <td>Torque is what will help a car ascent a steep ...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-09-30 22:10:09</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Torque is what will help a car ascent a steep...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.9868171811}, ...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.912877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1_d88vp4i</td>\n",
       "      <td>d8b3wiq</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-02 19:07:45</td>\n",
       "      <td>Thank you.\\nI don't really have the option of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nyxelestia</td>\n",
       "      <td>2016-10-02 19:07:45</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Thank you., \\nI don't really have the option ...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9974262118}, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1_d8b3wiq</td>\n",
       "      <td>d8cah3g</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-03 16:38:21</td>\n",
       "      <td>I would aim for the larger engine options with...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-10-03 16:38:21</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[I would aim for the larger engine options wit...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9396278858}, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_d8cah3g</td>\n",
       "      <td>d8d1dnj</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-04 02:40:55</td>\n",
       "      <td>This is so helpful, thank you! :)\\nOut of curi...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nyxelestia</td>\n",
       "      <td>2016-10-04 02:40:55</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[This is so helpful, thank you!, :), \\nOut of ...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9975322485}, ...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.608585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_d8d1dnj</td>\n",
       "      <td>d8dpmsl</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-04 16:33:02</td>\n",
       "      <td>An Accord will drive smoother/quieter than a C...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-10-04 16:33:02</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[An Accord will drive smoother/quieter than a ...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.944755733}, {...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.825754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124909</th>\n",
       "      <td>t1_ge7fc5x</td>\n",
       "      <td>ge7rel9</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 01:49:38</td>\n",
       "      <td>Thanks for your input. I only say I don't want...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>True</td>\n",
       "      <td>Skyline99x</td>\n",
       "      <td>2020-12-01 01:49:38</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Thanks for your input., I only say I don't wa...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.8439986706}, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.608585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124910</th>\n",
       "      <td>t1_ge7gmfe</td>\n",
       "      <td>ge7rr9x</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 01:52:49</td>\n",
       "      <td>Thanks for the in depth input. I honestly forg...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>True</td>\n",
       "      <td>Skyline99x</td>\n",
       "      <td>2020-12-01 01:52:49</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Thanks for the in depth input., I honestly fo...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9389728904}, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.217169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124911</th>\n",
       "      <td>t1_ge8ad5z</td>\n",
       "      <td>gea8j4i</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 18:36:15</td>\n",
       "      <td>Will consider. Do you know if maintenance is m...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>True</td>\n",
       "      <td>Skyline99x</td>\n",
       "      <td>2020-12-01 18:36:15</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Will consider., Do you know if maintenance is...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.8665452003}, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124912</th>\n",
       "      <td>t1_gea8j4i</td>\n",
       "      <td>geaant1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 18:53:00</td>\n",
       "      <td>A car this old I’d probably go to an independe...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>False</td>\n",
       "      <td>BalIsack</td>\n",
       "      <td>2020-12-01 18:53:00</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[A car this old I’d probably go to an independ...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8880066276}]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124913</th>\n",
       "      <td>t1_ge83cwu</td>\n",
       "      <td>gea8dpp</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 18:35:05</td>\n",
       "      <td>Thanks for the tips. Hopefully I'll find somet...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>True</td>\n",
       "      <td>Skyline99x</td>\n",
       "      <td>2020-12-01 18:35:05</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Thanks for the tips., Hopefully I'll find som...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9957450032}, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124914 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          parent_id comment_id  score_id          created_utc  \\\n",
       "0         t3_559xc5    d88vp4i         2  2016-09-30 22:10:09   \n",
       "1        t1_d88vp4i    d8b3wiq         1  2016-10-02 19:07:45   \n",
       "2        t1_d8b3wiq    d8cah3g         1  2016-10-03 16:38:21   \n",
       "3        t1_d8cah3g    d8d1dnj         1  2016-10-04 02:40:55   \n",
       "4        t1_d8d1dnj    d8dpmsl         2  2016-10-04 16:33:02   \n",
       "...             ...        ...       ...                  ...   \n",
       "1124909  t1_ge7fc5x    ge7rel9         1  2020-12-01 01:49:38   \n",
       "1124910  t1_ge7gmfe    ge7rr9x         1  2020-12-01 01:52:49   \n",
       "1124911  t1_ge8ad5z    gea8j4i         1  2020-12-01 18:36:15   \n",
       "1124912  t1_gea8j4i    geaant1         1  2020-12-01 18:53:00   \n",
       "1124913  t1_ge83cwu    gea8dpp         1  2020-12-01 18:35:05   \n",
       "\n",
       "                                                      body  score  \\\n",
       "0        Torque is what will help a car ascent a steep ...      2   \n",
       "1        Thank you.\\nI don't really have the option of ...      1   \n",
       "2        I would aim for the larger engine options with...      1   \n",
       "3        This is so helpful, thank you! :)\\nOut of curi...      1   \n",
       "4        An Accord will drive smoother/quieter than a C...      2   \n",
       "...                                                    ...    ...   \n",
       "1124909  Thanks for your input. I only say I don't want...      1   \n",
       "1124910  Thanks for the in depth input. I honestly forg...      1   \n",
       "1124911  Will consider. Do you know if maintenance is m...      1   \n",
       "1124912  A car this old I’d probably go to an independe...      1   \n",
       "1124913  Thanks for the tips. Hopefully I'll find somet...      1   \n",
       "\n",
       "                                                 permalink  is_submitter  \\\n",
       "0        /r/whatcarshouldIbuy/comments/559xc5/car_with_...         False   \n",
       "1        /r/whatcarshouldIbuy/comments/559xc5/car_with_...          True   \n",
       "2        /r/whatcarshouldIbuy/comments/559xc5/car_with_...         False   \n",
       "3        /r/whatcarshouldIbuy/comments/559xc5/car_with_...          True   \n",
       "4        /r/whatcarshouldIbuy/comments/559xc5/car_with_...         False   \n",
       "...                                                    ...           ...   \n",
       "1124909  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...          True   \n",
       "1124910  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...          True   \n",
       "1124911  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...          True   \n",
       "1124912  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...         False   \n",
       "1124913  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...          True   \n",
       "\n",
       "             author                date  \\\n",
       "0          pinks1ip 2016-09-30 22:10:09   \n",
       "1        Nyxelestia 2016-10-02 19:07:45   \n",
       "2          pinks1ip 2016-10-03 16:38:21   \n",
       "3        Nyxelestia 2016-10-04 02:40:55   \n",
       "4          pinks1ip 2016-10-04 16:33:02   \n",
       "...             ...                 ...   \n",
       "1124909  Skyline99x 2020-12-01 01:49:38   \n",
       "1124910  Skyline99x 2020-12-01 01:52:49   \n",
       "1124911  Skyline99x 2020-12-01 18:36:15   \n",
       "1124912    BalIsack 2020-12-01 18:53:00   \n",
       "1124913  Skyline99x 2020-12-01 18:35:05   \n",
       "\n",
       "                                                      link  \\\n",
       "0        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "2        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "3        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "4        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "...                                                    ...   \n",
       "1124909  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1124910  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1124911  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1124912  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1124913  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "\n",
       "                                             body_splitted  \\\n",
       "0        [Torque is what will help a car ascent a steep...   \n",
       "1        [Thank you., \\nI don't really have the option ...   \n",
       "2        [I would aim for the larger engine options wit...   \n",
       "3        [This is so helpful, thank you!, :), \\nOut of ...   \n",
       "4        [An Accord will drive smoother/quieter than a ...   \n",
       "...                                                    ...   \n",
       "1124909  [Thanks for your input., I only say I don't wa...   \n",
       "1124910  [Thanks for the in depth input., I honestly fo...   \n",
       "1124911  [Will consider., Do you know if maintenance is...   \n",
       "1124912  [A car this old I’d probably go to an independ...   \n",
       "1124913  [Thanks for the tips., Hopefully I'll find som...   \n",
       "\n",
       "                                                 sentiment  sentiment_score  \\\n",
       "0        [{'label': 'LABEL_0', 'score': 0.9868171811}, ...               -3   \n",
       "1        [{'label': 'LABEL_2', 'score': 0.9974262118}, ...                0   \n",
       "2        [{'label': 'LABEL_2', 'score': 0.9396278858}, ...                0   \n",
       "3        [{'label': 'LABEL_2', 'score': 0.9975322485}, ...               -2   \n",
       "4        [{'label': 'LABEL_2', 'score': 0.944755733}, {...                6   \n",
       "...                                                    ...              ...   \n",
       "1124909  [{'label': 'LABEL_2', 'score': 0.8439986706}, ...                2   \n",
       "1124910  [{'label': 'LABEL_2', 'score': 0.9389728904}, ...                4   \n",
       "1124911  [{'label': 'LABEL_2', 'score': 0.8665452003}, ...                0   \n",
       "1124912      [{'label': 'LABEL_1', 'score': 0.8880066276}]                0   \n",
       "1124913  [{'label': 'LABEL_2', 'score': 0.9957450032}, ...                0   \n",
       "\n",
       "         sentiment_score_avg  \n",
       "0                  -0.912877  \n",
       "1                   0.000000  \n",
       "2                   0.000000  \n",
       "3                  -0.608585  \n",
       "4                   1.825754  \n",
       "...                      ...  \n",
       "1124909             0.608585  \n",
       "1124910             1.217169  \n",
       "1124911             0.000000  \n",
       "1124912             0.000000  \n",
       "1124913             0.000000  \n",
       "\n",
       "[1124914 rows x 15 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e529183",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_json(\"comments_splitted_sentiment_score_scoreAvg.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af7f7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_json(\"comments_splitted_sentiment_score_scoreAvg.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551e4252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>body_splitted</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_score_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_559xc5</td>\n",
       "      <td>d88vp4i</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-30 22:10:09</td>\n",
       "      <td>Torque is what will help a car ascent a steep ...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-09-30 22:10:09</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Torque is what will help a car ascent a steep...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.9868171811}, ...</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.912877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1_d88vp4i</td>\n",
       "      <td>d8b3wiq</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-02 19:07:45</td>\n",
       "      <td>Thank you.\\nI don't really have the option of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nyxelestia</td>\n",
       "      <td>2016-10-02 19:07:45</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Thank you., \\nI don't really have the option ...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9974262118}, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1_d8b3wiq</td>\n",
       "      <td>d8cah3g</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-03 16:38:21</td>\n",
       "      <td>I would aim for the larger engine options with...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-10-03 16:38:21</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[I would aim for the larger engine options wit...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9396278858}, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_d8cah3g</td>\n",
       "      <td>d8d1dnj</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-04 02:40:55</td>\n",
       "      <td>This is so helpful, thank you! :)\\nOut of curi...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nyxelestia</td>\n",
       "      <td>2016-10-04 02:40:55</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[This is so helpful, thank you!, :), \\nOut of ...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9975322485}, ...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.608585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_d8d1dnj</td>\n",
       "      <td>d8dpmsl</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-04 16:33:02</td>\n",
       "      <td>An Accord will drive smoother/quieter than a C...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/559xc5/car_with_...</td>\n",
       "      <td>False</td>\n",
       "      <td>pinks1ip</td>\n",
       "      <td>2016-10-04 16:33:02</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[An Accord will drive smoother/quieter than a ...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.944755733}, {...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.825754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124909</th>\n",
       "      <td>t1_ge7fc5x</td>\n",
       "      <td>ge7rel9</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 01:49:38</td>\n",
       "      <td>Thanks for your input. I only say I don't want...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>True</td>\n",
       "      <td>Skyline99x</td>\n",
       "      <td>2020-12-01 01:49:38</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Thanks for your input., I only say I don't wa...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.8439986706}, ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.608585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124910</th>\n",
       "      <td>t1_ge7gmfe</td>\n",
       "      <td>ge7rr9x</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 01:52:49</td>\n",
       "      <td>Thanks for the in depth input. I honestly forg...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>True</td>\n",
       "      <td>Skyline99x</td>\n",
       "      <td>2020-12-01 01:52:49</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Thanks for the in depth input., I honestly fo...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9389728904}, ...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.217169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124911</th>\n",
       "      <td>t1_ge8ad5z</td>\n",
       "      <td>gea8j4i</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 18:36:15</td>\n",
       "      <td>Will consider. Do you know if maintenance is m...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>True</td>\n",
       "      <td>Skyline99x</td>\n",
       "      <td>2020-12-01 18:36:15</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Will consider., Do you know if maintenance is...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.8665452003}, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124912</th>\n",
       "      <td>t1_gea8j4i</td>\n",
       "      <td>geaant1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 18:53:00</td>\n",
       "      <td>A car this old I’d probably go to an independe...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>False</td>\n",
       "      <td>BalIsack</td>\n",
       "      <td>2020-12-01 18:53:00</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[A car this old I’d probably go to an independ...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8880066276}]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124913</th>\n",
       "      <td>t1_ge83cwu</td>\n",
       "      <td>gea8dpp</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-01 18:35:05</td>\n",
       "      <td>Thanks for the tips. Hopefully I'll find somet...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/whatcarshouldIbuy/comments/k47weg/hi_lookin...</td>\n",
       "      <td>True</td>\n",
       "      <td>Skyline99x</td>\n",
       "      <td>2020-12-01 18:35:05</td>\n",
       "      <td>https://www.reddit.com/r/whatcarshouldIbuy/com...</td>\n",
       "      <td>[Thanks for the tips., Hopefully I'll find som...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9957450032}, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124914 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          parent_id comment_id  score_id          created_utc  \\\n",
       "0         t3_559xc5    d88vp4i         2  2016-09-30 22:10:09   \n",
       "1        t1_d88vp4i    d8b3wiq         1  2016-10-02 19:07:45   \n",
       "2        t1_d8b3wiq    d8cah3g         1  2016-10-03 16:38:21   \n",
       "3        t1_d8cah3g    d8d1dnj         1  2016-10-04 02:40:55   \n",
       "4        t1_d8d1dnj    d8dpmsl         2  2016-10-04 16:33:02   \n",
       "...             ...        ...       ...                  ...   \n",
       "1124909  t1_ge7fc5x    ge7rel9         1  2020-12-01 01:49:38   \n",
       "1124910  t1_ge7gmfe    ge7rr9x         1  2020-12-01 01:52:49   \n",
       "1124911  t1_ge8ad5z    gea8j4i         1  2020-12-01 18:36:15   \n",
       "1124912  t1_gea8j4i    geaant1         1  2020-12-01 18:53:00   \n",
       "1124913  t1_ge83cwu    gea8dpp         1  2020-12-01 18:35:05   \n",
       "\n",
       "                                                      body  score  \\\n",
       "0        Torque is what will help a car ascent a steep ...      2   \n",
       "1        Thank you.\\nI don't really have the option of ...      1   \n",
       "2        I would aim for the larger engine options with...      1   \n",
       "3        This is so helpful, thank you! :)\\nOut of curi...      1   \n",
       "4        An Accord will drive smoother/quieter than a C...      2   \n",
       "...                                                    ...    ...   \n",
       "1124909  Thanks for your input. I only say I don't want...      1   \n",
       "1124910  Thanks for the in depth input. I honestly forg...      1   \n",
       "1124911  Will consider. Do you know if maintenance is m...      1   \n",
       "1124912  A car this old I’d probably go to an independe...      1   \n",
       "1124913  Thanks for the tips. Hopefully I'll find somet...      1   \n",
       "\n",
       "                                                 permalink  is_submitter  \\\n",
       "0        /r/whatcarshouldIbuy/comments/559xc5/car_with_...         False   \n",
       "1        /r/whatcarshouldIbuy/comments/559xc5/car_with_...          True   \n",
       "2        /r/whatcarshouldIbuy/comments/559xc5/car_with_...         False   \n",
       "3        /r/whatcarshouldIbuy/comments/559xc5/car_with_...          True   \n",
       "4        /r/whatcarshouldIbuy/comments/559xc5/car_with_...         False   \n",
       "...                                                    ...           ...   \n",
       "1124909  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...          True   \n",
       "1124910  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...          True   \n",
       "1124911  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...          True   \n",
       "1124912  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...         False   \n",
       "1124913  /r/whatcarshouldIbuy/comments/k47weg/hi_lookin...          True   \n",
       "\n",
       "             author                date  \\\n",
       "0          pinks1ip 2016-09-30 22:10:09   \n",
       "1        Nyxelestia 2016-10-02 19:07:45   \n",
       "2          pinks1ip 2016-10-03 16:38:21   \n",
       "3        Nyxelestia 2016-10-04 02:40:55   \n",
       "4          pinks1ip 2016-10-04 16:33:02   \n",
       "...             ...                 ...   \n",
       "1124909  Skyline99x 2020-12-01 01:49:38   \n",
       "1124910  Skyline99x 2020-12-01 01:52:49   \n",
       "1124911  Skyline99x 2020-12-01 18:36:15   \n",
       "1124912    BalIsack 2020-12-01 18:53:00   \n",
       "1124913  Skyline99x 2020-12-01 18:35:05   \n",
       "\n",
       "                                                      link  \\\n",
       "0        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "2        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "3        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "4        https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "...                                                    ...   \n",
       "1124909  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1124910  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1124911  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1124912  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "1124913  https://www.reddit.com/r/whatcarshouldIbuy/com...   \n",
       "\n",
       "                                             body_splitted  \\\n",
       "0        [Torque is what will help a car ascent a steep...   \n",
       "1        [Thank you., \\nI don't really have the option ...   \n",
       "2        [I would aim for the larger engine options wit...   \n",
       "3        [This is so helpful, thank you!, :), \\nOut of ...   \n",
       "4        [An Accord will drive smoother/quieter than a ...   \n",
       "...                                                    ...   \n",
       "1124909  [Thanks for your input., I only say I don't wa...   \n",
       "1124910  [Thanks for the in depth input., I honestly fo...   \n",
       "1124911  [Will consider., Do you know if maintenance is...   \n",
       "1124912  [A car this old I’d probably go to an independ...   \n",
       "1124913  [Thanks for the tips., Hopefully I'll find som...   \n",
       "\n",
       "                                                 sentiment  sentiment_score  \\\n",
       "0        [{'label': 'LABEL_0', 'score': 0.9868171811}, ...        -0.272727   \n",
       "1        [{'label': 'LABEL_2', 'score': 0.9974262118}, ...         0.000000   \n",
       "2        [{'label': 'LABEL_2', 'score': 0.9396278858}, ...         0.000000   \n",
       "3        [{'label': 'LABEL_2', 'score': 0.9975322485}, ...        -0.400000   \n",
       "4        [{'label': 'LABEL_2', 'score': 0.944755733}, {...         0.666667   \n",
       "...                                                    ...              ...   \n",
       "1124909  [{'label': 'LABEL_2', 'score': 0.8439986706}, ...         0.333333   \n",
       "1124910  [{'label': 'LABEL_2', 'score': 0.9389728904}, ...         0.444444   \n",
       "1124911  [{'label': 'LABEL_2', 'score': 0.8665452003}, ...         0.000000   \n",
       "1124912      [{'label': 'LABEL_1', 'score': 0.8880066276}]         0.000000   \n",
       "1124913  [{'label': 'LABEL_2', 'score': 0.9957450032}, ...         0.000000   \n",
       "\n",
       "         sentiment_score_avg  \n",
       "0                  -0.912877  \n",
       "1                   0.000000  \n",
       "2                   0.000000  \n",
       "3                  -0.608585  \n",
       "4                   1.825754  \n",
       "...                      ...  \n",
       "1124909             0.608585  \n",
       "1124910             1.217169  \n",
       "1124911             0.000000  \n",
       "1124912             0.000000  \n",
       "1124913             0.000000  \n",
       "\n",
       "[1124914 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd369f76",
   "metadata": {},
   "source": [
    "#### Steps to improve the whole dataset with the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73776682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
